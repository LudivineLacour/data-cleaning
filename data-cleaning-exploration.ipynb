{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoMa's collection data cleaning\n",
    "\n",
    "## Problem solving\n",
    "I'm working for the MoMa and they'd like to know in which department they need to enrich based on the current collection. \n",
    "\n",
    "**What is the Top-3 less valuable classification?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/museum_modern_art.csv',sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.rename(columns={'Unnamed: 0':'Id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop empty and useless tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_col=df1.isna().sum()\n",
    "null_col_percent=round(null_col[null_col>0]/df1.shape[0]*100,2)\n",
    "null_col_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols=null_col_percent[null_col_percent>50].index\n",
    "df2=df1.drop(drop_cols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df2.copy()\n",
    "df3.iloc[:,:].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df3.iloc[:,:].shape)\n",
    "df4=df3.iloc[:,:].drop_duplicates()\n",
    "print(df4.iloc[:,:].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put off parenthesis on text in relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parenthesis_col=['ArtistBio','Nationality','BeginDate','EndDate','Gender','Date']\n",
    "parenthesis_col\n",
    "\n",
    "df5=df4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in parenthesis_col:\n",
    "    df5[col]=df5[col].str.replace('\\(','').str.replace('\\)','')\n",
    "    \n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.iloc[:,:].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Date values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6=df5.copy()\n",
    "print(df6.Date.unique())\n",
    "start_values=df6.Date.nunique()\n",
    "print(\"total unique values in date: \",start_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.Date=df6.Date.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(date):\n",
    "    count_not_str=0\n",
    "    if type(date) != str:\n",
    "        count_not_str+=1\n",
    "    return count_not_str\n",
    "\n",
    "# Check if convert is working\n",
    "count_type=df6.Date.apply(test).value_counts()\n",
    "count_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_date(date):\n",
    "    if re.search('[0-9]{4}$', date):\n",
    "        return date[-4:]\n",
    "    if re.search('^[0-9]{4}', date):\n",
    "        return date[:4]\n",
    "    elif re.search('[0-9]{4}', date):\n",
    "        pos = re.search('[0-9]{4}', date).start()\n",
    "        return date[pos:pos+4]\n",
    "    elif re.search('[0-9]{3}\\?', date):\n",
    "        new_date = re.sub('\\?','0',date)\n",
    "        pos = re.search('[0-9]{4}', new_date).start()\n",
    "        return new_date[pos:pos+4]\n",
    "    elif re.search('^[a-zA-Z \\,\\?\\.]+$', date):\n",
    "        return np.nan\n",
    "    elif re.search('century',date):\n",
    "        return date[0]+str('00')\n",
    "    else:\n",
    "        return date\n",
    "    \n",
    "    \n",
    "# Testing function\n",
    "date='8th-9th century C.E.'\n",
    "new_date=clean_date(date)\n",
    "print(new_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8=df6.copy()\n",
    "before_clean2=df8.Date.nunique()\n",
    "print(\"total unique values in date before clean 2: \", before_clean2)\n",
    "\n",
    "df8.Date=df8.Date.apply(clean_date)\n",
    "\n",
    "print(df8.Date.value_counts())\n",
    "print(df8.Date.unique())\n",
    "clean2_values=df8.Date.nunique()\n",
    "print(\"total unique values in date after clean 2: \", clean2_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I won't use it - 1st way used to clean date values\n",
    "df6.loc[:,'Date']=df6.loc[:,'Date'].str.replace(\"'\",'').str.replace('.','').str.replace('early','').str.replace('s','').str.replace('c.','').str.replace('After','').str.replace('or before','').str.replace(' publihed','').str.replace('printed ','').str.replace('newpaperSeptember','').str.replace('exeted','').str.replace('Before','').str.replace(' ','')\n",
    "print(df6.Date.unique())\n",
    "clean1_values=df6.Date.nunique()\n",
    "print(\"total unique values in date after clean 1: \", clean1_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manually cleaning inconsistent data\n",
    "df9=df8.copy()\n",
    "cel=df9[(df9.Date=='November 10')&(df9.Artist=='George Platt Lynes')]\n",
    "df9.loc[cel.index,'Date']='1937'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manually cleaning inconsistent data\n",
    "cel2=df9[(df9.Date=='newspaper published March 30')]\n",
    "df9.loc[cel2.index,'Date']=np.nan\n",
    "df9.loc[(df9.Artist=='Jan Knap')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df9.Date.unique())\n",
    "clean3_values=df9.Date.nunique()\n",
    "print(\"total unique values in date after clean 3: \", clean3_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guess Missing Date Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9.Date.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop row with unknown artist and unknown date\n",
    "drop_row=df9[(df9.ConstituentID.isna())&(df9.Date.isna())].index\n",
    "df9_bis=df9.copy()\n",
    "df9_bis.drop(drop_row,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9_bis.Date.isna().sum()\n",
    "df9_bis[['ConstituentID','Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find list of artist with only nan dates\n",
    "total_per_artist = df9_bis.ConstituentID.value_counts()\n",
    "total_per_artist\n",
    "\n",
    "number_nan_per_artist = df9_bis[df9_bis.Date.isna()].ConstituentID.value_counts()\n",
    "\n",
    "list_artist_nan_date=[]\n",
    "\n",
    "for a in number_nan_per_artist.iteritems():\n",
    "    artist = a[0]\n",
    "    number_of_nan = a[1]\n",
    "    if total_per_artist.loc[artist] == number_of_nan:\n",
    "        list_artist_nan_date.append(artist)\n",
    "\n",
    "len(list_artist_nan_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep rows excluding list of artist with only nan dates\n",
    "df9_bis=df9_bis[-df9_bis.ConstituentID.isin(list_artist_nan_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10=df9_bis.copy()\n",
    "\n",
    "# create a copy of dataframe and delete nan date to calculate the mean date of every artist\n",
    "null_date=df10.loc[df10.Date.isna()].index\n",
    "df10.drop(null_date,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date as int to work with mean\n",
    "df10.Date=df10.Date.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean for every artist\n",
    "mean_date=round(df10.groupby('ConstituentID')['Date'].agg('mean'))\n",
    "mean_date=mean_date.astype(int)\n",
    "mean_date[mean_date.index=='27'][0]\n",
    "mean_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_date.loc['9971']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return the mean of the constituentID\n",
    "def getmean(x):\n",
    "    # x string\n",
    "    if x in mean_date.index:\n",
    "        return mean_date.loc[x]\n",
    "    return\n",
    "\n",
    "# Testing the function\n",
    "test_tab=df9[['ConstituentID','Date']]\n",
    "test_date=test_tab[test_tab.ConstituentID=='27']\n",
    "\n",
    "test_date.Date=test_date.Date.fillna(test_date['ConstituentID'].apply(getmean))\n",
    "test_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing 2nd times with several artist\n",
    "test_date_bis=test_tab[test_tab.ConstituentID.isin(['27','4930'])]\n",
    "\n",
    "test_date_bis.Date=test_date_bis.Date.fillna(test_date_bis['ConstituentID'].apply(getmean))\n",
    "test_date_bis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11=df9_bis.copy()\n",
    "\n",
    "df11.Date=df11.Date.fillna(df11['ConstituentID'].apply(getmean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11.Date=df11.Date.astype(int)\n",
    "df11[df11.Date==700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[\"690-1850\"]\n",
    "cutoffs=[690]\n",
    "         \n",
    "for i in range(1850,2020,10):\n",
    "    cutoffs.append(i)\n",
    "    labels.append(str(i+1)+\"-\"+str(i+10))\n",
    "\n",
    "cutoffs.append(2020)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11['DateRange']=pd.cut(df11.Date, cutoffs,labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1st way to get the dataframe\n",
    "bar=df11.groupby('DateRange')['Id'].agg('count').reset_index()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df99 = pd.DataFrame(df11.DateRange.value_counts()).reset_index()\n",
    "df99.columns=[\"DateRange\",\"Count\"]\n",
    "df99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "fig,ax=plt.subplots(figsize=(20,8))\n",
    "barchart=sns.barplot(data=df99,  x='DateRange',y='Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
